{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata=pd.read_csv(\"Frogs_MFCCs.csv\",header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "features=rawdata.iloc[:,:22]\n",
    "labels=rawdata.iloc[:,22:25]\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.30, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.array(X_train)\n",
    "y_train=np.array(y_train)\n",
    "X_test=np.array(X_test)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "def Encode(a,b):\n",
    "    le = LabelEncoder()\n",
    "    ohe = OneHotEncoder()\n",
    "    \n",
    "    r=a.shape[0]\n",
    "    a_encode=np.empty([r,0])\n",
    "    b_encode=np.empty([r,0])\n",
    "    c=a.shape[1]\n",
    "    for i in range(c):\n",
    "        le.fit(a[:,i])\n",
    "        y1=le.transform(a[:,i])\n",
    "        y2=le.transform(b[:,i])\n",
    "        ohe.fit(y1.reshape(-1, 1))\n",
    "        e1=ohe.transform(y1.reshape(-1, 1)).toarray()\n",
    "        e2=ohe.transform(y2.reshape(-1, 1)).toarray()\n",
    "        a_encode=np.hstack((a_encode,e1))\n",
    "        b_encode=np.hstack((b_encode,e1))\n",
    "    return a_encode,b_encode\n",
    "\n",
    "def Train(X_train,y_train,X_test,y_test,svc,parameters,Smote=False):\n",
    "    r=y_test.shape[0]\n",
    "    y_pred=np.empty([r,0])\n",
    "    c=y_test.shape[1]\n",
    "    for i in range(c):\n",
    "        y_train_col=y_train[:,i]\n",
    "        y_test_col=y_test[:,i]\n",
    "        \n",
    "        if __name__ == '__main__':\n",
    "            clf = GridSearchCV(svc, parameters, cv=10,n_jobs=5)\n",
    "            if not Smote:\n",
    "                clf.fit(X_train, y_train_col)\n",
    "            else:\n",
    "                X_train_smote, y_train_smote = SMOTE().fit_sample(X_train, y_train_col)\n",
    "                clf.fit(X_train_smote, y_train_smote)\n",
    "            print (\"The parameters and score of the\"+str(i)+\"th label in the train set\")\n",
    "            print(clf.best_params_)\n",
    "            print(clf.score(X_train,y_train_col))\n",
    "\n",
    "            best_model = clf.best_estimator_\n",
    "            best_model.fit(X_train, y_train_col)\n",
    "            y_pred_col=best_model.predict(X_test)\n",
    "            y_pred=np.hstack((y_pred,y_pred_col.reshape(r,1)))\n",
    "    y_test_encode,y_pred_encode=Encode(y_test,y_pred)\n",
    "    print ('The hamming loss of the multi-labels in the test set')\n",
    "    print (hamming_loss(y_test_encode, y_pred_encode))\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Encode1(a):\n",
    "    le = LabelEncoder()\n",
    "    ohe = OneHotEncoder()\n",
    "    \n",
    "    r=a.shape[0]\n",
    "    a_encode=np.empty([r,0])\n",
    "    c=a.shape[1]\n",
    "    for i in range(c):\n",
    "        le.fit(a[:,i])\n",
    "        y1=le.transform(a[:,i])\n",
    "        ohe.fit(y1.reshape(-1, 1))\n",
    "        e1=ohe.transform(y1.reshape(-1, 1)).toarray()\n",
    "        a_encode=np.hstack((a_encode,e1))\n",
    "    return a_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Encode2(a):\n",
    "    le = LabelEncoder()\n",
    "    r=a.shape[0]\n",
    "    a_encode=np.empty([r,0])\n",
    "    c=a.shape[1]\n",
    "    for i in range(c):\n",
    "        le.fit(a[:,i])\n",
    "        y1=le.transform(a[:,i])\n",
    "        a_encode=np.hstack((a_encode,y1.reshape(-1,1)))\n",
    "    return a_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters and score of the0th label in the train set\n",
      "{'C': 5, 'gamma': 0.1}\n",
      "1.0\n",
      "The parameters and score of the1th label in the train set\n",
      "{'C': 3, 'gamma': 0.1}\n",
      "1.0\n",
      "The parameters and score of the2th label in the train set\n",
      "{'C': 5, 'gamma': 0.01}\n",
      "0.9948371723590151\n",
      "The hamming loss of the multi-labels in the test set\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "C_range = [1,3,5]\n",
    "gamma_range = np.logspace(-3, 1, 5)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "svc=SVC(kernel='rbf',decision_function_shape='ovr')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    Train(X_train,y_train,X_test,y_test,svc,param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters and score of the0th label in the train set\n",
      "{'C': 3}\n",
      "0.9384432088959491\n",
      "The parameters and score of the1th label in the train set\n",
      "{'C': 5}\n",
      "0.9567116759332804\n",
      "The parameters and score of the2th label in the train set\n",
      "{'C': 5}\n",
      "0.9642573471008737\n",
      "The hamming loss of the multi-labels in the test set\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "l1_svc=LinearSVC(penalty='l1',dual=False)\n",
    "C_range2 = [1,3,5]\n",
    "param_grid2 = dict(C=C_range2)\n",
    "Train(X_train,y_train,X_test,y_test,l1_svc,param_grid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters and score of the0th label in the train set\n",
      "{'C': 3}\n",
      "0.9251389992057188\n",
      "The parameters and score of the1th label in the train set\n",
      "{'C': 5}\n",
      "0.9295075456711676\n",
      "The parameters and score of the2th label in the train set\n",
      "{'C': 3}\n",
      "0.9648530579825259\n",
      "The hamming loss of the multi-labels in the test set\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "Train(X_train,y_train,X_test,y_test,l1_svc,param_grid2,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.datasets import fetch_mldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_estimator__C': 3, 'base_estimator__gamma': 0.029470517025518096}\n"
     ]
    }
   ],
   "source": [
    "Y_train,Y_test=Encode(y_train,y_test)\n",
    "\n",
    "\n",
    "C_range = [3]\n",
    "gamma_range = np.logspace(-3, 1)\n",
    "param_grid = dict(base_estimator__gamma=gamma_range, base_estimator__C=C_range)\n",
    "svc=SVC(kernel='rbf',decision_function_shape='ovr')\n",
    "\n",
    "\n",
    "chains = [ClassifierChain(svc, order='random', random_state=i)\n",
    "          for i in range(1)]\n",
    "GS=[]\n",
    "for chain in chains:\n",
    "    clf = GridSearchCV(chain, param_grid, cv=2)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    print(clf.best_params_)\n",
    "    GS.append(clf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test=Encode1(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_chains1 = np.array([clf.predict(X_test) for clf in GS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_jaccard_scores = [jaccard_similarity_score(Y_test1, Y_pred_chain >= .5)\n",
    "                        for Y_pred_chain in Y_pred_chains1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_ensemble = Y_pred_chains1.mean(axis=0)\n",
    "ensemble_jaccard_score = jaccard_similarity_score(Y_test, Y_pred_ensemble >= .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.988335649220318"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hamming loss of the multi-labels in the test set using classifier chains is\n",
      "0.0024843151290580654\n"
     ]
    }
   ],
   "source": [
    "print ('The hamming loss of the multi-labels in the test set using classifier chains is')\n",
    "print (hamming_loss(Y_test, Y_pred_chains1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_estimator__C': 1}\n",
      "{'base_estimator__C': 1}\n",
      "{'base_estimator__C': 1}\n"
     ]
    }
   ],
   "source": [
    "Y_train=Encode1(y_train)\n",
    "Y_test=Encode1(y_test)\n",
    "\n",
    "\n",
    "C_range = [1,3,5]\n",
    "param_grid_2 = dict(base_estimator__C=C_range)\n",
    "l1_svc=LinearSVC(penalty='l1',dual=False)\n",
    "\n",
    "\n",
    "chains = [ClassifierChain(l1_svc, order='random', random_state=i)\n",
    "          for i in range(3)]\n",
    "GS=[]\n",
    "for chain in chains:\n",
    "    clf = GridSearchCV(chain, param_grid_2, cv=2)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    print(clf.best_params_)\n",
    "    GS.append(clf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_chains = np.array([clf.predict(X_test) for clf in GS])\n",
    "chain_jaccard_scores = [jaccard_similarity_score(Y_test, Y_pred_chain >= .5)\n",
    "                        for Y_pred_chain in Y_pred_chains]\n",
    "Y_pred_ensemble = Y_pred_chains.mean(axis=0)\n",
    "ensemble_jaccard_score = jaccard_similarity_score(Y_test, Y_pred_ensemble >= .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9506561679790027, 0.9346302300447739, 0.9452601513046163]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_jaccard_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.951466728423653"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_jaccard_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hamming loss of the multi-labels in the test set using classifier chains L1 penalty is\n",
      "0.02126405322329361\n"
     ]
    }
   ],
   "source": [
    "print ('The hamming loss of the multi-labels in the test set using classifier chains L1 penalty is')\n",
    "print (hamming_loss(Y_test, Y_pred_chains[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import LabelPowerset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=Encode1(y_train)\n",
    "Y_test=Encode1(y_test)\n",
    "\n",
    "\n",
    "C_range = [1,3,5]\n",
    "param_grid_2 = dict(base_estimator__C=C_range)\n",
    "l1_svc=LinearSVC(penalty='l1',dual=False)\n",
    "lp = LabelPowerset(classifier=l1_svc, require_dense=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelPowerset(classifier=LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l1', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "       require_dense=[True, True])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp.fit(X_train,Encode2(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2=lp.transform(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_smote, y_train_smote = SMOTE().fit_sample(X_train, y2.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_estimator__C': 5}\n"
     ]
    }
   ],
   "source": [
    "chains = [ClassifierChain(l1_svc, order='random', random_state=i)\n",
    "          for i in range(1)]\n",
    "GS=[]\n",
    "for chain in chains:\n",
    "    clf = GridSearchCV(chain, param_grid_2, cv=2)\n",
    "    clf.fit(X_train_smote, y_train_smote.reshape(-1,1))\n",
    "    print(clf.best_params_)\n",
    "    GS.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5456229735988883]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_chains2 = np.array([clf.predict(X_test) for clf in GS])\n",
    "chain_jaccard_scores = [jaccard_similarity_score(lp.transform(Encode2(y_test)), Y_pred_chain >= .5)\n",
    "                        for Y_pred_chain in Y_pred_chains2]\n",
    "Y_pred_ensemble = Y_pred_chains2.mean(axis=0)\n",
    "ensemble_jaccard_score = jaccard_similarity_score(lp.transform(Encode2(y_test)), Y_pred_ensemble >= .5)\n",
    "chain_jaccard_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hamming loss of the multi-labels in the test set using classifier chains L1 penalty after SMOTE is\n",
      "0.4548402037980547\n"
     ]
    }
   ],
   "source": [
    "print ('The hamming loss of the multi-labels in the test set using classifier chains L1 penalty after SMOTE is')\n",
    "print (hamming_loss(lp.transform(Encode2(y_test)), Y_pred_chains2[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def confusion_matrix(y_test, y_pred):\n",
    "    if len(y_test.shape) != 2:\n",
    "        raise IOError('y_test must be a 2D array (Matrix)')\n",
    "    elif len(y_pred.shape) != 2:\n",
    "        raise IOError('y_pred must be a 2D array (Matrix)')\n",
    "\n",
    "    cm = np.zeros((y_test.shape[1], y_test.shape[1]))\n",
    "\n",
    "    for obs in range(0, len(y_pred[:, 0])):\n",
    "        j = y_pred[obs, :].argmax()\n",
    "        i = y_test[obs, :].argmax()\n",
    "        cm[i, j] += 1\n",
    "\n",
    "    accuracy = 0.0\n",
    "    for i in range(0, cm.shape[1]):\n",
    "        accuracy += cm[i, i]\n",
    "    accuracy /= len(y_test.argmax(axis=1))\n",
    "    print (\"Accuracy on the test-set: \" + str(accuracy))\n",
    "\n",
    "    return cm\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion Matrix', cmap=plt.cm.Reds):\n",
    "    plt.ion()\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        if np.isnan(cm).any():\n",
    "            np.nan_to_num(cm, copy=False)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment='center',\n",
    "                 color='white' if cm[i, j] > thresh else 'black')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ioff()\n",
    "\n",
    "\n",
    "def draw_cm(y_test, y_pred, classes, normalize=False):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plot_confusion_matrix(cm, classes, normalize)\n",
    "\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train2(X_train,y_train,X_test,y_test,svc,parameters,Smote=False):\n",
    "    r=y_test.shape[0]\n",
    "    y_pred=np.empty([r,0])\n",
    "    c=y_test.shape[1]\n",
    "    for i in range(c):\n",
    "        y_train_col=y_train[:,i]\n",
    "        y_test_col=y_test[:,i]\n",
    "        \n",
    "        if __name__ == '__main__':\n",
    "            clf = GridSearchCV(svc, parameters, cv=10,n_jobs=5)\n",
    "            if not Smote:\n",
    "                clf.fit(X_train, y_train_col)\n",
    "            else:\n",
    "                X_train_smote, y_train_smote = SMOTE().fit_sample(X_train, y_train_col)\n",
    "                clf.fit(X_train_smote, y_train_smote)\n",
    "            \n",
    "\n",
    "            best_model = clf.best_estimator_\n",
    "            best_model.fit(X_train, y_train_col)\n",
    "            y_pred_col=best_model.predict(X_test)\n",
    "            y_pred=np.hstack((y_pred,y_pred_col.reshape(r,1)))\n",
    "    y_test_encode,y_pred_encode=Encode(y_test,y_pred)\n",
    "    return y_test_encode,y_pred_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_range = [1,3,5]\n",
    "gamma_range = np.logspace(-3, 1, 5)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "svc=SVC(kernel='rbf',decision_function_shape='ovr')\n",
    "#classif = OneVsRestClassifier(svc)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    aa,bb=Train2(X_train,y_train,X_test,y_test,svc,param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test-set: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  20.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.],\n",
       "       [   0.,  155.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.],\n",
       "       [   0.,    0.,  657.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.],\n",
       "       [   0.,    0.,    0., 1327.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.]])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(aa, bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(aa,bb,average='macro')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
